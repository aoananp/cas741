\documentclass[12pt, titlepage]{article}

\usepackage[margin=1.0in]{geometry}
\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage{booktabs}
\usepackage{caption}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

% For easy change of table widths
\newcommand{\colZwidth}{1.0\textwidth}
\newcommand{\colAwidth}{0.13\textwidth}
\newcommand{\colBwidth}{0.82\textwidth}
\newcommand{\colCwidth}{0.1\textwidth}
\newcommand{\colDwidth}{0.05\textwidth}
\newcommand{\colEwidth}{0.8\textwidth}
\newcommand{\colFwidth}{0.17\textwidth}
\newcommand{\colGwidth}{0.5\textwidth}
\newcommand{\colHwidth}{0.28\textwidth}

\newcounter{tnum} %Functional Test
\newcommand{\tthetestnum}{\thetnum}
\newcommand{\tref}[1]{T\ref{#1}}

\input{../Comments}
\newcommand{\famname}{LODES} % PUT YOUR PROGRAM NAME HERE
\newcommand{\famdesc}{Library of ODE Solvers}
\newcommand{\famurl}{https://github.com/aoananp/cas741/}
\newcommand{\unittesturl}{https://www.mathworks.com/help/matlab/matlab_prog/author-class-based-unit-tests-
in-matlab.html}

\begin{document}

\title{Test Plan for the Library of ODE Solvers (LODES)} 
\author{Paul Aoanan}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}
\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
\today & 1.0 & Initial draft.\\
%Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}
The following table lists the symbols, abbreviations and acronyms used in the Test Plan.
The software library's Commonality Analysis (CA) tables provide supplementary items in addition to the ones 
listed below.\\
\begin{table} [h]
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l l l |} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  CA & Commonality Analysis\\
  IDE & Integrated Development Environment\\ 
  IVP & Initial Value Problem\\
  ODE & Ordinary Differential Equation\\
  \famname{} & \famdesc{}\\
  SRS & Software Requirements Specification\\
  T & Test\\
  O & Output\\
  \bottomrule
\end{tabular}\\
  \caption{Symbols, Abbreviations, and Acronyms used in the Test Plan}
  \label{Table:Table_Symbols}
\end{table}

~\newpage

\tableofcontents

\listoftables

%\listoffigures

\newpage

\pagenumbering{arabic}

%This document ...

\section{General Information}
The following section provides an overview of the Test Plan for the Library of Ordinary Differential Equation (ODE) 
Solvers.\\  \wss{You do not need to end your paragraphs with this symbol.  A
  hard return and a newline will end the paragraph.}
  \wpa{Thank you - noted.}
  
This section explains the purpose of this document, the scope of the system, and an overview of the following 
sections.

\wss{This ``roadmap'' doesn't really make sense.  You start with describing the
  ``following section'' and then  you introduce ``this section.''  Is the
  following section 3.1 or 4?  Some kind of introduction before the ``roadmap''
  would also make sense.  You can put this document in context.  What is the
  project?  What other documentation exists.  In particular, you should point to
  the SRS.  You should also give the GitHub url where the project is located.}

\subsection{Purpose}
The main purpose of this document (the Test Plan) is to describe the verification and validation process that will 
be used to test the functionality of \famname{}.  This document closely follows the requirements and governs
the subsequent testing activities. This document is intended to be used as a reference for all testing and will be
used to increase confidence in the 
software implementation.  \wss{I deleted the extra newline you inserted.  You
  are nearly always best to go with the LaTeX default formatting and not start
  manually inserting newlines.}

This document will be used as a guide and starting point for the Test Report. The test cases
listed in this document will be executed and the output will be analyzed to uncover errors, increase confidence 
and correctness in the software.

\subsection{Scope}
The scope of the testing is limited to the \famdesc{}. Given the appropriate inputs, each program in \famname{} is 
intended to find
the solution to an Initial Value Problem (IVP).\\
\\
Due to time and cost constraints, the scope of testing is limited to automated unit and manual system verification 
and validation activities.\\
\\
Static testing will be briefly described and will be left to the developer and verifier to perform with due diligence.

\subsection{Overview of Document}
The following sections provide more detail about the testing of \famname{}.
Information about the testing process is provided and the software specifications
that were discussed in the Commonality Analysis are stated.
The evaluation process that will be followed during testing is outlined and test cases
for both the system testing and unit testing are provided.

\section{Plan}
This section provides a description of the software that is being tested, the team that will
perform the testing, the approach to automated testing, the tools to be used for verification,
and the non-testing based verification. 
	
\subsection{Software Description}
The software being tested is the \famdesc{}. Given the ODE, initial values of $x$ and $y$, and the final value of 
$x$,
the programs calculate the final value of $y$ through the use of numerical methods.

\subsection{Test Team}

The test team that will execute the test cases, write and review the Test Report consists of:
\begin{itemize}
 \item Paul Aoanan
 \item To be determined (The test report will be reviewed by an independent individual)
\end{itemize} 

\subsection{Automated Testing Approach}
Automated unit testing will be implemented for \famname{} as described in Section \ref{sec_verificationtools}.
A combination of the Unit Testing Framework and MATLAB's Test Class will be used for automated testing.

%Since MATLAB only offers commercially available testing libraries, the scope of automated testing in this Test
%Plan is limited to unit testing.

\subsection{Verification Tools} \label{sec_verificationtools}
The verification tools to be used will be the following:

\begin{enumerate}
\item{Unit Testing Framework\\}
A Unit Testing Framework designed in MATLAB that will compare MATLAB's own functional programs
with \famname{}' running the same inputs will be implemented.

The following algorithm \wss{say equation, not algorithm} will be implemented to
compare the results:
$$\epsilon_{\text{relative}} = \frac{\text{Result}_\text{MATLAB} - \text{Result}_\text{\famname{}}} {\text{Result}
_\text{MATLAB}} $$

\wss{The above equation will give you an error for every instant of time where
  you do the calculations; that is, you will have an error for each time step.
This could let you build some nice plots, but the vector of numbers on its own
is too much for a person to take in.  You should also have a scalar value to
assess the error.  Specifically, you should take the norm of your
$\epsilon_\text{relative}$ vector.  Any vector norm is fine, as long as you say
which one you are using.}

\item{MATLAB's Test Class\\}
MATLAB's Test Class (matlab.unittest.testcase) will be used for providing the framework for automated
system testing. The documentation can be referenced in \href{\unittesturl}{MATHWORKS}.

\item{Static Analyer\\} \wss{proof read}
The program's IDE (MATLAB) will be used as a Static Analyzer tool for program debugging and
for checking syntax errors.

\item{Continuous Integration\\}
The source code and the project repository is located in GitHub at: \url{\famurl}.
It provides the Build Server functionality to fully maintain and document the software through its lifecycle.
As well, it provides the compare functionality for future regression testing and
analysis of code updates.  \wss{How does the build server find Matlab?  This is
  something you should look into sooner than later, since it might require
  something special to deal with the Matlab licensing.}

\item{Code Coverage Tool\\}
Due to the commercial nature of MATLAB, only commercial code coverage tools are viable for use due to the 
maturity, increased confidence, and detailed documentation that they offer. Other coverage tools may be 
considered, but no code coverage tool will be considered in the scope of this
test plan due to budget constraints. \wss{Okay -- good to be explicit.}

\end{enumerate}

%\wss{Thoughts on what tools to use, such as the following: unit testing
%  framework, valgrind, static analyzer, make, continuous integration, test
%  coverage tool, etc.}

% \subsection{Testing Schedule}
		
% See Gantt Chart at the following url ...

\subsection{Non-Testing Based Verification}
\famname{} will undergo the following non-testing based verification activities:

\paragraph{Code Inspection\\}
\famname{} will undergo an initial desk review by an independent body.  The code
will be perused for syntax errors and correct program calls.  This code
inspection activity provides the initial sanity check for the developer, the
reviewer, and the software.  \wss{You should be more specific about how you are
  going to run the code inspection.  Probably you want to give a checklist for
  the reviewer to follow.  A google search will find you many checklists that
  could give you a good starting point.  The checklist should be included in
  your appendix.}

\paragraph{Code Walkthrough\\}
\famname{} will undergo code walkthrough by the developer and an independent
body.  They will jointly review the code and reference the Commonality Analysis
for algorithm adherence. This activity will also involve logic analysis, loop
and recursion boundary tracing (using by-hand test cases), passing of variables
and references, and if the code is programmatically correct. The code
walkthrough will be executed with the guidance laid out in Section
\ref{checklist}.  \wss{Great to see that you have additional details.  If I have
  any comments on the walkthrough, I'll make them when I review that section.}

\paragraph{Symbolic Execution\\}
Generally, symbolic execution will be performed using the boundary input conditions. Test conditions will be
analyzed and executed by-hand. Generally, inputs in, on, and around the boundary
conditions are chosen.  \wss{Are you doing symbolic execution?  There isn't
  enough information here.  What software
  tool are you using?}

%\wss{List any approaches like code inspection, code walkthrough, symbolic
%execution etc.  Enter not applicable if that is the case.}

\wss{I am glad to see code inspection, code walkthroughs and symbolic execution
  mentioned.  Your implementation will be fairly straightforward.  To represent
  a graduate level of effort, you need these ``extras.''}

\section{System Test Description}
System testing will be executed to provide increased confidence that \famname{} will achieve the goals defined in 
the Commonality Analysis. It uses a "black box" \wss{quotes in LaTeX are done as
  ``quotes.''   That is, there is a different symbol for the opening and closing
  quotation marks.}  approach wherein it tests the system as a whole through the use 
of input and output analysis.

\subsection{Tests for Faulty Input}

\subsubsection{Input}
		
The input will be based on the Assumptions table in the Commonality Analysis. Each test will correspond to an 
entry from the assumptions item whilst altering a specific input variable to a non-permissible value. The list of 
inputs is in order with the entries in the table.

\begin{table} [H]
  \caption{Faulty Input Test Cases}
  \label{Table:Table_FaultyInputs}  
\begin{tabular}{|c|p{8cm}|p{6cm}|}
  \hline	
  \textbf{Number} & \textbf{Input} &\textbf{Expected Outcome}\\
  \hline 
  01 & ODE Function Call $\mathbb{\notin}$ \{euler741, trap741, heun741, rk4741\} $\mathbb{\cup}$ 
  MATLAB functions & error: undefined function call\\ \hline
  02& $f(x, y) = y'' + y' + x + 2$ & success: false\\ \hline
  03& $f(x, y) = y' + 1$ & success: false\\ \hline
  04& $f(x, y) = (dx/dy) + 1$ & success: false\\ \hline
  05& $f(x, y) = (y + 1) / x$ & success: false\\ \hline
  06& $f(x, y) = y/(x-3)$ & success: false\\ \hline
  07& Boundary Value Problem & success: false\\ \hline
  08& $h = -1$ & success: false\\ \hline
  09& $h = 0$ & success: false\\ \hline
  10& $x_0 = i$ & success: false\\ \hline 
  11& $x_0 = [0, 1]$ & success: false\\ \hline 
  12& $y_0 = i$ & success: false\\ \hline 
  13& $y_0 = [0, 1]$ & success: false\\ \hline
  14& $x_k = i$ & success: false\\ \hline 
  15& $x_k = [0, 1]$ & success: false\\ \hline

\end{tabular}\\
\end{table}

\wss{I would like more information in this table.  Why is the success false?  I
  assume that for 02 this is because it is a second order ode, but you should
  make this explicit.  Also, I might have missed something new in Matlab, but
  how exactly are derivatives represented?  Are you using symbolic programming,
  like for Maple?  If you are just passing a function, then $y''$ won't have any
  semantic meaning.}

\subsection{Tests for Functional Requirements}

\subsubsection{Calculation Tests}
		
\paragraph{Euler's Method}

\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-euler_simple}: Simple Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 2, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 3$, success = true
					
How test will be performed: Automated system test  \wss{For these test cases, it
  would be nice to see the symbolic form of the closed-form solution.  As it is
  right now, a reviewer would have to derive the closed-form solution and then
  verify if your output is correct.  Your test cases might actually come from
  symbolically solving the algorithm.  If this is the case, you really need to
  make it clear.}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-euler_simpleiterative}: Simple-Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 0.5, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 5.0625$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-euler_nonlinear}: Non-linear Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 5, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -4$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-euler_nonlineariterative}: Non-linear Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 1, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -0.669532$, success = true
					
How test will be performed: Automated system test

\end{enumerate}

\paragraph{Trapezoid Method}
\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-trap_simple}: Simple Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 2, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 3$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-trap_simpleiterative}: Simple-Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 0.5, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 5.0625$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-trap_nonlinear}: Non-linear Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 5, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -4$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-trap_nonlineariterative}: Non-linear Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 1, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -0.6695$, success = true
					
How test will be performed: Automated system test

\end{enumerate}

\paragraph{Heun's Method}
\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-heun_simple}: Simple Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 2, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 5$, success = true
					
How test will be performed: Automated system test

\wss{It looks like you are repeating inputs for different tests.  I think this
  is a great idea, since there really is no reason to make up different
  arbitrary tests for each method.  However, repeating all of this information
  and leaving it to the reader to deduce the differences isn't really fair to
  them.  I suggest that instead of presenting each test separately,  you build a
  table that summarizes all of the related tests.  It would take less space and
  it would be easier to review.}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-heun_simpleiterative}: Simple-Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 0.5, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 6.972900$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-heun_nonlinear}: Non-linear Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 5, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -43.897311$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-heun_nonlineariterative}: Non-linear Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 1, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -1.101197$, success = true
					
How test will be performed: Automated system test

\end{enumerate}

\paragraph{Runge-Kutta Method}
\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-rk_simple}: Simple Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 2, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 7$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-rk_simpleiterative}: Simple-Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = y, h = 0.5, x_0 = 0, y_0 = 1, x_k = 2$
					
Output: $y_k = 7.383970$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-rk_nonlinear}: Non-linear Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 5, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -1702.845129$, success = true
					
How test will be performed: Automated system test

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-rk_nonlineariterative}: Non-linear Iterative Case}}

Type: Functional, Automated, System %Functional, Dynamic, Manual, Static etc.
					
Initial State: Not applicable
					
Input: $f(x, y) = sin(x) - y^2, h = 1, x_0 = 0, y_0 = 1, x_k = 5$
					
Output: $y_k = -1.028367$, success = true
					
How test will be performed: Automated system test

\end{enumerate}

%\subsubsection{Area of Testing2}
%
%...

\wss{Your outputs are unlikely to be an exact match.  There will be some epsilon
  error.  You mention this at the start, but it isn't clear that it is applied
  here.  Part of your output could be a summary of the observed errors for each
  test output in comparison to the ideal output.}

\wss{Are you just taking one step for each of these tests?  You really also need
  tests that will predict the ODE values for a sequence of steps.}

\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Performance Requirements}
		
\paragraph{Speed}

\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-speed}: Speed Benchmark}}

Type: Non-Functional, Automated, Performance 
					
Initial State: Not Applicable
					
Input/Condition: $f(x, y) = sin(x) - y^2, h = 1E-5, x_0 = 0, y_0 = 1, x_k = 5$
					
Output/Result: $\sigma_\text{\famname{}} \leq 4*\sigma_\text{MATLAB}$ (\famname{}' runtimes shall be no more 
than four (4) times that of MATLAB's.)  \wss{Use a symbolic constant here, so
  that it is easy to change.  Also, this requirement should be in the SRS.  Is
  it there?  If not, you should add it.}
					
How test will be performed: Using MATLAB's Run and Time functionality, the execution time of a program will be 
measured and compared through program calls to the respective MATLAB and \famname{} functions.\

\end{enumerate}

\wss{Is this just one step of the ODE solver?  I don't think you'll be able to
  measure any difference between the different methods with one step.
  Everything will happen too fast.  You should have a long integration time to
  let the tiny speed differences accumulate.}

\subsubsection{Results Analysis}

\paragraph{Benchmark Results}

\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-benchmark}: MATLAB Benchmark}}

Type: Non-Functional, Automated, Precision 
					
Initial State: Not Applicable
					
Input/Condition: $f(x, y) = sin(x) - y^2, h = \text{(VARIABLE)}, x_0 = 0, y_0 = 1, x_k = 5$
					
Output/Result: The $\epsilon_{\text{relative}}$ vs. $h$ plot.
The $y_k$ values will be compared according to the following formula -
$$\epsilon_{\text{relative}} = \frac{\text{Result}_\text{MATLAB} - \text{Result}_\text{\famname{}}} {\text{Result}
_\text{MATLAB}} $$
					
How test will be performed: The $h$ (step-size) values will be varied across the range (0, 1000]. 
$\epsilon_{\text{relative}}$ will be plotted against $h$.

\end{enumerate}

\wss{Good idea for a plot, but you'll need to run the simulations long enough to
  observe differences as mentioned above.}

\wss{I don't think I see a test related to accuracy where you compare the
  different ODE solvers to a known closed form solution over time.  In your
  original planning for this project you were thinking that the purpose of your
  program was to do this comparison.  I persuaded you to instead focus on a
  library of ODE solvers, suggesting that you can return to this idea for
  testing.  It is time now to return to your original idea.  :-)  It would be a great
  plot to show how the error differs between your different methods.}

%\item{test-id2\\}
%
%Type: Functional, Dynamic, Manual, Static etc.
%					
%Initial State: 
%					
%Input: 
%					
%Output: 
%					
%How test will be performed: 

%\subsubsection{Area of Testing2}
%
%...

\subsection{Traceability Between Test Cases and Requirements}
The following table shows the traceability mapping for the test cases laid out in this Test Plan to the requirements 
described in the Commonality Analysis.

\begin{table} [H]
  \caption{Requirements Traceability Matrix}
  \label{Table:Table_Traceability}  
\begin{tabular}{|c|p{8cm}|}
  \hline	
  \textbf{Test Number} & \textbf{CA Requirements}\\
  \hline 
   T1& IM1, O1, O2, O3, O4, O5\\ \hline
   T2& IM1, O1, O2, O3, O4, O5\\ \hline
   T3& IM1, O1, O2, O3, O4, O5\\ \hline
   T4& IM1, O1, O2, O3, O4, O5\\ \hline
   T5& IM2, O1, O2, O3, O4, O5\\ \hline
   T6& IM2, O1, O2, O3, O4, O5\\ \hline
   T7& IM2, O1, O2, O3, O4, O5\\ \hline
   T8& IM2, O1, O2, O3, O4, O5\\ \hline
   T9& IM3, O1, O2, O3, O4, O5\\ \hline
   T10& IM3, O1, O2, O3, O4, O5\\ \hline
   T11& IM3, O1, O2, O3, O4, O5\\ \hline
   T12& IM3, O1, O2, O3, O4, O5\\ \hline
   T13& IM4, O1, O2, O3, O4, O5\\ \hline
   T14& IM4, O1, O2, O3, O4, O5\\ \hline
   T15& IM4, O1, O2, O3, O4, O5\\ \hline
   T16& IM4, O1, O2, O3, O4, O5\\ \hline
   T17& NFR1\\ \hline
   T18& Future NFR2\\ \hline

\end{tabular}\\
\end{table}
				
\section{Unit Testing Plan}
		
%\wss{Unit testing plans for internal functions and, if appropriate, output
% files}

\subsubsection{ODE String Parser}

\paragraph{Parser Functionality}

\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-parser1}: Simple}}

Type: Functional, Manual, Unit 
					
Initial State: Not Applicable
					
Input/Condition: $f(x, y) = ax^2 + by^2 - cx - dy - 1$
					
Output/Result: Machine-interpreted $f(x, y)$
					
How test will be performed: $f(x, y)$ will be passed into the parser function and the output shall be a
machine-interpreted function.

\wss{Are you implementing a parser?  I thought that Matlab was just taking care
  of this?}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-parser1}: Trigonometric}}

Type: Functional, Manual, Unit 
					
Initial State: Not Applicable
					
Input/Condition: $f(x, y) = sin^2(x) - y^3$
					
Output/Result: Machine-interpreted $f(x, y)$
					
How test will be performed: $f(x, y)$ will be passed into the parser function and the output shall be a
machine-interpreted function.

\end{enumerate}

\wss{I don't understand why there is a trigonometric unit test?  You aren't
  planning on implementing trigonometric functions (I don't think) and you don't
  need to test Matlab.}

\wss{For the unit tests you really shouldn't try to be specific until you have
  done your design.  This section was intended to be an overview of your plans
  for selecting unit test cases.}

\paragraph{Function Iteration}

\begin{enumerate}

\item{\textbf{T-\refstepcounter{tnum}\thetnum \label{t-difference}: Program Iteration}}

Type: Functional, Manual, Unit 
					
Initial State: Not Applicable
					
Input/Condition: $f(x, y) = y, h = .1, x_0 = 0, y_0 = 1, x_k = 1$
					
Output/Result: $y_k$ through each time step

How test will be performed: Each iteration of the loops or recursions in the code will be observed in run-time.
Each variable will be monitored prior to loop or function re-entry. This will be done through all four methods (Euler, 
Trapezoid, Heun, and Runge-Kutta).

\end{enumerate}

\bibliographystyle{plainnat}

\bibliography{SRS}

\newpage

\section{Appendix}

\subsection{Walkthrough Questionnaire} \label{checklist}
\begin{enumerate}
\item{Are there defects in the code?}
\item{Does the code adhere to MATLAB coding standards and guidelines (syntax, function calls, etc.)?}
\item{Does the code sensibly apply the ODE solvers as defined in the Commonality Analysis?}
\item{Does the code contain spelling errors?}
\item{Do the recursion/loops have the correct terminating cases according to the formulas defined in the Commonality Analysis?}
\item{Does the code have the correct inputs and outputs?}  \wss{What does this
    mean?  Do you mean whether it agrees with the requirements?}
\item{Do the datatypes in the code adhere to ones defined in the requirements and specifications?}
\item{Does the code satisfy the ranges and assumptions defined in the Commonality Analysis?}
\end{enumerate}

\wss{This isn't actually a code walkthrough procedure.  This is a code
  inspection checklist.  A walkthrough is when a group of reviewers ``play
  computer'' and go through the code and its algorithms by hand.}

%This is where you can place additional information.
\pagebreak

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\renewcommand{\arraystretch}{1.2}
%\noindent \begin{tabularx}{1.0\textwidth}{l l X}
\noindent \begin{longtable*}{l l p{12cm}} \toprule
\textbf{symbol} & \textbf{unit} & \textbf{description}\\
\midrule
$\epsilon$ & none & The measure of the difference/error between results obtained with \famname{}
and MATLAB.\\
$\sigma$ & seconds & The measure of time a program executes.\\

\bottomrule
\end{longtable*}

\subsection{Usability Survey Questions}
No usability study will be performed for \famname{}.

%This is a section that would be appropriate for some teams.

\end{document}
