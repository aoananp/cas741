\documentclass[12pt, titlepage]{article}

\usepackage[margin=1.0in]{geometry}
\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage{booktabs}
\usepackage{caption}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

% For easy change of table widths
\newcommand{\colZwidth}{1.0\textwidth}
\newcommand{\colAwidth}{0.13\textwidth}
\newcommand{\colBwidth}{0.82\textwidth}
\newcommand{\colCwidth}{0.1\textwidth}
\newcommand{\colDwidth}{0.05\textwidth}
\newcommand{\colEwidth}{0.8\textwidth}
\newcommand{\colFwidth}{0.17\textwidth}
\newcommand{\colGwidth}{0.5\textwidth}
\newcommand{\colHwidth}{0.28\textwidth}

\newcounter{ftnum} %Functional Test
\newcommand{\ftthefttestnum}{\theftnum}
\newcommand{\ftref}[1]{FT\ref{#1}}

\input{../Comments}
\newcommand{\famname}{LODES} % PUT YOUR PROGRAM NAME HERE
\newcommand{\famdesc}{Library of ODE Solvers}
\newcommand{\famurl}{https://github.com/aoananp/cas741/}

\begin{document}

\title{Test Plan for the Library of ODE Solvers (LODES)} 
\author{Paul Aoanan}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}
\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
\today & 1.0 & Initial draft.\\
%Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}
The following table lists the symbols, abbreviations and acronyms used in the Test Plan.
The software library's Commonality Analysis (CA) tables provide supplementary items in addition to the ones listed below.\\
\begin{table} [h]
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l l l |} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  CA & Commonality Analysis\\
  IDE & Integrated Development Environment\\ 
  IVP & Initial Value Problem\\
  ODE & Ordinary Differential Equation\\
  \famname{} & \famdesc{}\\
  SRS & Software Requirements Specification\\
  T & Test\\
  O & Output\\
  \bottomrule
\end{tabular}\\
  \caption{Symbols, Abbreviations, and Acronyms used in the Test Plan}
  \label{Table:Table_Symbols}
\end{table}

~\newpage

\tableofcontents

\listoftables

\listoffigures

\newpage

\pagenumbering{arabic}

%This document ...

\section{General Information}
The following section provides an overview of the Test Plan for the Library of Ordinary Differential Equation (ODE) Solvers.\\
This section explains the purpose of this document, the scope of the system, and an overview of the following sections.

\subsection{Purpose}
The main purpose of this document (the Test Plan) is to describe the verification and validation process that will be used to test the
functionality of \famname{}.  This document closely follows the requirements and governs the subsequent testing activities.
This document is intended to be used as a reference for all testing and will be used to increase confidence in the software implementation.\\
\\
This document will be used as a guide and starting point for the Test Report. The test cases
listed in this document will be executed and the output will be analyzed to uncover errors, increase confidence and correctness in the software.

\subsection{Scope}
The scope of the testing is limited to the \famdesc{}. Given the appropriate inputs, each program in \famname{} is intended to find
the solution to an Initial Value Problem (IVP).\\

\subsection{Overview of Document}
The following sections provide more detail about the testing of \famname{}.
Information about the testing process is provided and the software specifications
that were discussed in the Commonality Analysis are stated.
The evaluation process that will be followed during testing is outlined and test cases
for both the system testing and unit testing are provided.

\section{Plan}
This section provides a description of the software that is being tested, the team that will
perform the testing, the approach to automated testing, the tools to be used for verification, and the non-testing based verification. 
	
\subsection{Software Description}
The software being tested is the \famdesc{}. Given the ODE, initial values of $x$ and $y$, and the final value of $x$,
the programs calculate the final value of $y$ through the use of numerical methods.

\subsection{Test Team}

The test team that will execute the test cases, write and review the Test Report consists of:
\begin{itemize}
 \item Paul Aoanan
 \item To be determined (A separate test report will be reviewed by an independent individual)
\end{itemize} 

\subsection{Automated Testing Approach}
Automated testing will be implemented for \famname{}. It will consist of developing test cases that target the boundary conditions in the code 

\subsection{Verification Tools}
The verification tools to be used will be the following:

\begin{enumerate}
\item{Unit Testing Framework\\}
A Unit Testing Framework designed in MATLAB that will compare MATLAB's own functional programs
with
\famname{}' running the same inputs will be implemented.

The following algorithm will be implemented to compare the results:
$$\Delta_{\text{relative}} = \frac{\text{Result}_\text{MATLAB} - \text{Result}_\text{\famname{}}} {\text{Result}_\text{MATLAB}} $$

\item{Static Analyer\\}
The program's IDE (MATLAB) will be used as a Static Analyzer tool for program debugging and
for checking syntax errors.

\item{Continuous Integration\\}
The source code and the project repository is located in GitHub at: \url{\famurl}.
It provides the Build Server functionality to fully maintain and document the software through its lifecycle.
As well, it provides the compare functionality for future regression testing and analysis of code updates.

\item{Code Coverage Tool\\}
Due to the commercial nature of MATLAB, only commercial code coverage tools are viable for use due to the maturity, increased confidence, and detailed documentation that they offer. Other coverage tools may be considered, but no code coverage tool will be considered in the scope of this test plan due to budget constraints.

\end{enumerate}

%\wss{Thoughts on what tools to use, such as the following: unit testing
%  framework, valgrind, static analyzer, make, continuous integration, test
%  coverage tool, etc.}

% \subsection{Testing Schedule}
		
% See Gantt Chart at the following url ...

\subsection{Non-Testing Based Verification}
\famname{} will undergo the following non-testing based verification activities:

\paragraph{Code Inspection\\}
\famname{} will undergo an initial desk review by the developer. Whilst it is preferred to have an independent body conducting this verification activity, the developer himself will peruse his own code for syntax errors and correct program calls. This code inspection activity provides the initial sanity check for the developer and the software.

\paragraph{Code Walkthrough\\}
\famname{} will undergo code walkthrough by the developer. Again, whilst it is preferred to have an independent body conducting this verification activity, the developer himself will peruse his code and reference the Commonality Analysis for algorithm adherence. This activity will also involve logic analysis, loop and recursion boundary tracing (using by-hand test cases), passing of variables and references, and if the code is programmatically correct.

\paragraph{Symbolic Execution\\}
Generally, symbolic execution will be performed using the boundary input conditions. Test conditions will be analyzed and executed by-hand. Generally, inputs in, on, and around the boundary conditions are chosen.

%\wss{List any approaches like code inspection, code walkthrough, symbolic
%execution etc.  Enter not applicable if that is the case.}

\section{System Test Description}
System testing will be executed to provide increased confidence that \famname{} will achieve the goals defined in the Commonality Analysis. It uses a "black box" approach wherein it tests the system as a whole through the use of input and output analysis.

\subsection{Tests for Faulty Input}

\subsubsection{Input}
		
The input will be based on the Assumptions table in the Commonality Analysis. Each test will correspond to an entry from the assumptions item whilst altering a specific input variable to a non-permissible value. The list of inputs is in order with the entries in the table.

\begin{table} [H]
  \caption{Fauly Input Test Cases}
  \label{Table:Table_FaultyInputs}  
\begin{tabular}{|r|p{8cm}|p{6cm}|}
  \hline	
  \textbf{Number} & \textbf{Input} &\textbf{Expected Outcome}\\
  \hline 
  01 & ODE Function Call $\mathbb{\notin}$ \{euler741, trap741, heun741, rk4741\} $\mathbb{\cup}$ 
  MATLAB functions & error: undefined function call\\ \hline
  
  02& $f(x, y) = y'' + y' + x + 2$ & error: input out of bounds\\
  
  
  \hline
\end{tabular}\\

\end{table}


\subsection{Tests for Functional Requirements}

\subsubsection{Faulty Input Exception}
		
\paragraph{Input Assumption Tests}

\begin{enumerate}

\item{FT-\refstepcounter{ftnum}\theftnum \label{ft-inputdesk}}

Type: Static %Functional, Dynamic, Manual, Static etc.
					
Initial State: The code "as-is"
					
Input: The source code as the input to this test
					
Output: Error / exception prompts 
					
How test will be performed: The code will undergo desk review to check for the presence of error exception handling prompts if the inputs do not adhere to the boundaries defined in the input assumptions

\item{FT-\refstepcounter{ftnum}\theftnum \label{ft-in}}

Type:  Functional, Dynamic, Manual, Static etc.
					
Initial State: The code "as-is"
					
Input: The source code as the input to this test
					
Output: Error / exception prompts
					
How test will be performed: The code will undergo desk review to check for the presence of error exception handling prompts if the inputs do not adhere to the boundaries defined in the input assumptions

\item{FT-\refstepcounter{ftnum}\theftnum \label{ft-walkthrough}}

Type: Static %Functional, Dynamic, Manual, Static etc.
					
%Initial State: The source code "as-is"
%					
%Input: The source code as the input to this test
%					
%Output: The code's adherence to the goals of the program.
%					
%How test will be performed: The code will undergo desk review to determine, in closed bounds and within reason, if the code satisfies the machine implementation of the mathematical formulas listed in the Commonality Analysis.
%
%\item{FT-\refstepcounter{ftnum}\theftnum \label{ft-walkthrough}}
%
%Type: Static %Functional, Dynamic, Manual, Static etc.
%					
%Initial State: The source code "as-is"
%					
%Input: The source code as the input to this test
%					
%Output: The code's adherence to the goals of the program.
%					
%How test will be performed: The code will undergo desk review to determine, in closed bounds and within reason, if the code satisfies the machine implementation of the mathematical formulas listed in the Commonality Analysis.
					
\item{FT-\refstepcounter{ftnum}\theftnum \label{ft-}}

Type: Functional, Dynamic, Manual, Static etc. %Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Area of Testing1}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{test-id1\\}

Type: 
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

% \section{Tests for Proof of Concept}

% \subsection{Area of Testing1}
		
% \paragraph{Title for Test}

% \begin{enumerate}

% \item{test-id1\\}

% Type: Functional, Dynamic, Manual, Static etc.
					
% Initial State: 
					
% Input: 
					
% Output: 
					
% How test will be performed: 
					
% \item{test-id2\\}

% Type: Functional, Dynamic, Manual, Static etc.
					
% Initial State: 
					
% Input: 
					
% Output: 
					
% How test will be performed: 

% \end{enumerate}

% \subsection{Area of Testing2}

% ...
				
\section{Unit Testing Plan}
		
\wss{Unit testing plans for internal functions and, if appropriate, output
  files}

\bibliographystyle{plainnat}

\bibliography{SRS}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

This is a section that would be appropriate for some teams.

\end{document}
